seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3)))
# display the summary
summary(seg4)
seg4a <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3,10)))
# display the summary
summary(seg4a)
seg4a <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3,5,10)))
# display the summary
summary(seg4a)
seg4a <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3,10)))
# display the summary
summary(seg4a)
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(tol = 1e-05, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20, tol = 1e-05, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 2, tol = 1e-05, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20,tol = 1e-04, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20,tol = 1e-03, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20,tol = 1e-02, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20,tol = 1, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20,tol = 1e-07, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20,tol = 1e-09, it.max = 50, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = NA,
seg.control(K = 20,tol = 1e-09, it.max = 100, fix.npsi=FALSE))
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi =c(3))
# display the summary
summary(seg4)
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 3 based on when the rule change was announced,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi =c(3,10))
# display the summary
summary(seg4)
# get breakpoints
seg4$psi
# get the slopes
slope(seg4)
# get the fitted data
my.fitted <- fitted(seg4)
my.model <- data.frame(year = df.tourney$year, X3PAr = my.fitted)
# plot the fitted model
ggplot(my.model, aes(x = year, y = X3PAr)) + geom_line()
# Replot things
cols <- c("Simple OLS"='#EE3838',"Segmented OLS"='#78C4D4')
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", aes(col = '#EE3838'), se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr, color = '#78C4D4'),
linetype = "solid", size=1) +
scale_colour_identity(name="Model Type",
breaks = c('#EE3838','#78C4D4'),
labels = c("Simple OLS", "Segmented OLS break between 9 and 10"),
guide = "legend")  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
### Method to search: Test for Breakpoints
davies.test(lm1, ~time)
seg6 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(9.3)))
davies.test(seg6, ~time)
davies.test(seg7, ~time)
seg7 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3.1, 9.3)))
summary(seg7)
seg7 <- segmented(lm1,
seg.Z = ~ as.factor(time),
psi = list(time = c(3.1, 9.3)))
seg7 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3.1, 9.3)))
summary(seg7)
seg7 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3.1, 9.3)))
summary(seg7)
lin_seg = AIC(seg7)
lin_seg_AIC = AIC(seg7)
mm_final_AIC = AIC(lmer9a)
lin_seg_AIC = AIC(seg7)
mm_final_AIC = AIC(lmer9a)
simple_OLS_AIC = AIC(lm1)
lin_seg_AIC = AIC(seg7)
mm_final_AIC = AIC(lmer9a)
lmer2_AIC = AIC(lmer2)
simple_OLS_AIC = AIC(lm1)
lmer2_AIC = AIC(lmer2)
lmer3d_AIC = AIC(lmer3d)
lin_seg_AIC = AIC(seg7)
mm_final_AIC = AIC(lmer9a)
AICs = c(simple_OLS_AIC,lmer2_AIC, lmer3d_AIC, lin_seg_AIC,mm_final_AIC)
AICs
titles = c("Simple OLS",
"Simple Random Intercepts",
"Simple Random Slopes and Intercepts",
"Segmented OLS",
"Segmented Random Slopes and Intercepts")
data.frame(titles, AICs)
anova(lmer3d, lmer9a)
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
geom_segment(aes(x = 2003, y = lmer9fn(2003,0,0), xend = 2006, yend = lmer9fn(2006,0,0),
colour = '#EE3838'),
data = df.tourney) +
geom_segment(aes(x = 2007, y = lmer9fn(2007,1,0), xend = 2012, yend = lmer9fn(2012,1,0),
colour = '#78C4D4'),
data = df.tourney) +
geom_segment(aes(x = 2013, y = lmer9fn(2013,0,1), xend = 2017, yend = lmer9fn(2017,0,1),
colour = '#4B5973'),
data = df.tourney) +
geom_vline(xintercept = 2012.5) +
geom_vline(xintercept = 2006.5) +
scale_colour_identity(name="Model Type:",
breaks = c('#EE3838','#78C4D4','#4B5973'),
labels = c("2003-2006", "2007-2012", "2012-2013"),
guide = "legend") +
annotate(geom="label", x = 2012.5, y = 0, label = "NBA Revolution", fill ="#F2F2F2", color = "black") +
annotate(geom="label", x = 2006.5, y = 0, label = "NCAA Rule Change", fill ="#F2F2F2", color = "black") +
labs(title="3PAr Over Time - Segmented Mixed Model") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
geom_segment(aes(x = 2003, y = lmer9fn(2003,0,0), xend = 2006, yend = lmer9fn(2006,0,0),
colour = '#EE3838'),
data = df.tourney) +
geom_segment(aes(x = 2007, y = lmer9fn(2007,1,0), xend = 2012, yend = lmer9fn(2012,1,0),
colour = '#78C4D4'),
data = df.tourney) +
geom_segment(aes(x = 2013, y = lmer9fn(2013,0,1), xend = 2018, yend = lmer9fn(2018,0,1),
colour = '#4B5973'),
data = df.tourney) +
geom_vline(xintercept = 2012.5) +
geom_vline(xintercept = 2006.5) +
scale_colour_identity(name="Model Type:",
breaks = c('#EE3838','#78C4D4','#4B5973'),
labels = c("2003-2006", "2007-2012", "2012-2013"),
guide = "legend") +
annotate(geom="label", x = 2012.5, y = 0, label = "NBA Revolution", fill ="#F2F2F2", color = "black") +
annotate(geom="label", x = 2006.5, y = 0, label = "NCAA Rule Change", fill ="#F2F2F2", color = "black") +
labs(title="3PAr Over Time - Segmented Mixed Model") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
anova(lmer3d, lmer9a)
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
geom_segment(aes(x = 2003, y = lmer9fn(2003,0,0), xend = 2006, yend = lmer9fn(2006,0,0),
colour = '#EE3838'),
data = df.tourney) +
geom_segment(aes(x = 2007, y = lmer9fn(2007,1,0), xend = 2012, yend = lmer9fn(2012,1,0),
colour = '#78C4D4'),
data = df.tourney) +
geom_segment(aes(x = 2013, y = lmer9fn(2013,0,1), xend = 2018, yend = lmer9fn(2018,0,1),
colour = '#4B5973'),
data = df.tourney) +
geom_vline(xintercept = 2012.5) +
geom_vline(xintercept = 2006.5) +
scale_colour_identity(name="Model Type:",
breaks = c('#EE3838','#78C4D4','#4B5973'),
labels = c("2003-2006", "2007-2012", "2012-2018"),
guide = "legend") +
annotate(geom="label", x = 2012.5, y = 0, label = "NBA Revolution", fill ="#F2F2F2", color = "black") +
annotate(geom="label", x = 2006.5, y = 0, label = "NCAA Rule Change", fill ="#F2F2F2", color = "black") +
labs(title="3PAr Over Time - Segmented Mixed Model") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
geom_segment(aes(x = 2003, y = lmer9fn(2003,0,0), xend = 2006, yend = lmer9fn(2006,0,0),
colour = '#EE3838'),
data = df.tourney) +
geom_segment(aes(x = 2007, y = lmer9fn(2007,1,0), xend = 2012, yend = lmer9fn(2012,1,0),
colour = '#78C4D4'),
data = df.tourney) +
geom_segment(aes(x = 2013, y = lmer9fn(2013,0,1), xend = 2018, yend = lmer9fn(2018,0,1),
colour = '#4B5973'),
data = df.tourney) +
geom_vline(xintercept = 2012.5) +
geom_vline(xintercept = 2006.5) +
scale_colour_identity(name="Model Type:",
breaks = c('#EE3838','#78C4D4','#4B5973'),
labels = c("2003-2006", "2007-2012", "2013-2018"),
guide = "legend") +
annotate(geom="label", x = 2012.5, y = 0, label = "NBA Revolution", fill ="#F2F2F2", color = "black") +
annotate(geom="label", x = 2006.5, y = 0, label = "NCAA Rule Change", fill ="#F2F2F2", color = "black") +
labs(title="3PAr Over Time - Segmented Mixed Model") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
# since we know that games are increasing can we make those statistics into
# proportions to control for the specific effect
get_newprop = cbind(df.tourney$School, get_prop_df(df.tourney))
get_newprop
df.clean.noschool = df.clean[,2:length(df.clean)]
top_cor_list = cor(df.clean.noschool)[,ncol(df.clean.noschool)-1]
top_cor_list = sort(top_cor_list, decreasing = TRUE)
top_cor_list = top_cor_list[3:length(top_cor_list)]
top_cor_list
list_top = names(top_cor_list)
list_top
# graphs
df.clean.noschool %>%
group_by(time) %>%
summarise(mean_games = mean(G)) %>%
ggplot(df.clean.noschool, mapping = aes(x = time + 2003, y = mean_games)) +
geom_line(stat="identity") + ggtitle("Games Played Per Season in the NCAA") +
ylim(25, 35) +
xlab("Year") +
ylab("Games")+
theme_hodp()
# we noticed that games also increases over time (it's one of the top predictors)
plot(df.clean.noschool$time, df.clean.noschool$G)
# graphs
df.clean.noschool %>%
group_by(time) %>%
summarise(mean_games = mean(G)) %>%
ggplot(df.clean.noschool, mapping = aes(x = time + 2003, y = mean_games)) +
geom_line(stat="identity") + ggtitle("Games Played Per Season in the NCAA") +
ylim(25, 35) +
xlab("Year") +
ylab("Games")+
theme_hodp()
# we noticed that games also increases over time (it's one of the top predictors)
plot(df.clean.noschool$time, df.clean.noschool$G)
# since we know that games are increasing can we make those statistics into
# proportions to control for the specific effect
get_newprop = cbind(df.tourney$School, get_prop_df(df.tourney))
get_newprop
df.clean.noschool = df.clean[,2:length(df.clean)]
top_cor_list = cor(df.clean.noschool)[,ncol(df.clean.noschool)-1]
top_cor_list = sort(top_cor_list, decreasing = TRUE)
top_cor_list = top_cor_list[3:length(top_cor_list)]
top_cor_list
list_top = names(top_cor_list)
list_top
# graphs
df.clean.noschool %>%
group_by(time) %>%
summarise(mean_games = mean(G)) %>%
ggplot(df.clean.noschool, mapping = aes(x = time + 2003, y = mean_games)) +
geom_line(stat="identity") + ggtitle("Games Played Per Season in the NCAA") +
ylim(25, 35) +
xlab("Year") +
ylab("Games")+
theme_hodp()
# we noticed that games also increases over time (it's one of the top predictors)
plot(df.clean.noschool$time, df.clean.noschool$G)
# Let's have X3PAr be our response
# Check assumption of normal distribution
p <- ggplot(df.tourney, aes(x=X3PAr)) +
geom_histogram(colour="black", fill='#EE3838') +
labs(title="3PAr Histogram") +
xlab("3PAr") +
ylab("Counts") +
theme_hodp()
p
### Model 2: Mixed Model, fixed effect of time, random intercept stratified on School
lmer2 <- lmer(X3PAr ~ time + (1 | School), data=df.tourney)
summary(lmer2)
coef(summary(lmer2))
coef(lmer2)$School
### Fitting a random slopes, random intercepts model is often failing to converge
lmer3 <- lmer(X3PAr ~ time + (1  + time|School), data=df.tourney) # fails to converge
# Mixed Model Segmented - coaching change
lmer8 <- lmer(X3PAr ~ time*same.coach + (1  + time|School) , data=df.tourney) # fails to converge
# Use all fit to find a model that converges
# Source: https://joshua-nugent.github.io/allFit/
ncores <- detectCores()
diff_optims <- allFit(lmer8, maxfun = 1e6, parallel = 'multicore', ncpus = ncores)
is.OK <- sapply(diff_optims, is, "merMod")
diff_optims.OK <- diff_optims[is.OK]
lapply(diff_optims.OK,function(x) x@optinfo$conv$lme4$messages)
# Nelder_Mead for convergence
lmer8a <- update(lmer8, control=lmerControl(optimizer="Nelder_Mead"))
### COMPARE
# Fixed coefs
coef(summary(lmer8a))
# Look at differences b/w individual schools coefs
head(coef(lmer8a)$School)
### Let's do some plots
# Get coefficients
year <- 2003:2017
intercept.false <- summary(lmer8a)$coef[1,1]
slope.false <- summary(lmer8a)$coef[2,1]
intercept.true <- summary(lmer8a)$coef[3,1]
slope.true <- summary(lmer8a)$coef[4,1]
lmer8fn <- function(year, true_flag) {
return(intercept.false + (year - 2003) * slope.false +
intercept.true*true_flag + slope.true * (year - 2003) * true_flag)
}
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
geom_segment(aes(x = 2003, y = lmer8fn(2003,0), xend = 2017, yend = lmer8fn(2017,0),
colour = '#EE3838'),
data = df.tourney) +
geom_segment(aes(x = 2003, y = lmer8fn(2003,1), xend = 2017, yend = lmer8fn(2017,1),
colour = '#78C4D4'),
data = df.tourney) +
scale_colour_identity(name="Model Type",
breaks = c('#EE3838','#78C4D4'),
labels = c("Coaching Change", "Same Coach"),
guide = "legend") +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
### Contrast t-tests ###
### Slope
# Create a vector of coefficients
coefs <- summary(lmer9a)$coef[,1]
coefs
# Construct our vector of differences C
C = c(0,0,0,0,-1,0)
# Calculate the contrast t-statistic via matrix multiplication
estimate = t(coefs)%*%C
std.err =sqrt(t(C) %*%vcov(Model3) %*%C)
contrast.t = estimate/std.err; contrast.t
std.err =sqrt(t(C) %*%vcov(lmer9a) %*%C)
contrast.t = estimate/std.err; contrast.t
df.residual(lmer9a)
lmer9a
# P-value using 76 degrees of freedom, two-sided test
p.value = 2*(1-pt(abs(contrast.t),df=df.residual(lmer9a) - 2));
df.residual(lmer9a)
# P-value using 76 degrees of freedom, two-sided test
p.value = 2*(1-pt(abs(contrast.t),df=df.residual(lmer9a)[1] - 2));
df.residual(lmer9a) - 2
as.numeric(df.residual(lmer9a))
# P-value using 76 degrees of freedom, two-sided test
p.value = 2*(1-pt(abs(contrast.t),df=2);
# P-value using 76 degrees of freedom, two-sided test
p.value = 2*(1-pt(abs(contrast.t),df=2));
contrast.t
# P-value using 76 degrees of freedom, two-sided test
p.value = 2*(1-pt(abs(contrast.t[1]),df=df.residual(lmer9a) - 2));
paste("Our p-value is:", round(p.value,4))
paste("Our p-value is:", p.value)
contrast.t
return(contrast.t, p.value, str)
return(list(contrast.t, p.value, str))
contrast_test <- function(C, coefs) {
estimate = t(coefs)%*%C
std.err =sqrt(t(C) %*%vcov(lmer9a) %*%C)
contrast.t = estimate/std.err
# P-value using 76 degrees of freedom, two-sided test
p.value = 2*(1-pt(abs(contrast.t[1]),df=df.residual(lmer9a) - 2));
str = paste("Our p-value is:", p.value)
return(list(contrast.t, p.value, str))
}
source('helpers.R')
# P-value using 76 degrees of freedom, two-sided test
p.value = 2*(1-pt(abs(contrast.t[1]),df=df.residual(lmer9a) - 2));
contrast_test(C,coefs)
contrast_test_lmer9a <- function(C, coefs) {
estimate = t(coefs)%*%C
std.err =sqrt(t(C) %*%vcov(lmer9a) %*%C)
contrast.t = estimate/std.err
p.value = 2*(1-pt(abs(contrast.t[1]),df=df.residual(lmer9a) - 2));
return(list(tstat=contrast.t, pval = p.value))
}
contrast_test_lmer9a(C,coefs)
### Contrast t-tests ###
# Test if slopes are significantly different
# Create a vector of coefficients to test if difference between slope for
# era0*time and era1*time is 0 or not
coefs <- summary(lmer9a)$coef[,1]
coefs
# Test if difference between slope forera0*time and era2*time is 0 or not
# Construct our vector of differences C
C = c(0,0,0,0,0,-1)
contrast_test_lmer9a(C,coefs)
# Test if difference between slope forera0*time and era2*time is 0 or not
# Construct our vector of differences C
C = c(0,0,0,0,1,-1)
contrast_test_lmer9a(C,coefs)
# EDA plot to show how average 3Ar changes with time
df.tourney %>%
group_by(time) %>%
summarise(mean_three = mean(X3PAr)) %>%
ggplot(df.tourney, mapping = aes(x = time + 2003, y = mean_three)) +
geom_line(stat="identity") + ggtitle("Average 3PAr Across the NCAA") +
xlab("Year") +
ylab("3PAr")+
theme_hodp()
sorted_alpha_school = df.tourney[order(df.tourney$School),]
# EDA plot to show how average 3Ar changes with time
df.tourney %>%
group_by(time) %>%
summarise(mean_three = mean(X3PAr)) %>%
ggplot(df.tourney, mapping = aes(x = time + 2003, y = mean_three)) +
geom_line(stat="identity") + ggtitle("Average 3PAr Across the NCAA") +
xlab("Year") +
ylab("3PAr")+
theme_hodp()
sorted_alpha_school = df.tourney[order(df.tourney$School),]
sorted_alpha_prop = get_newprop[order(get_newprop$`df.tourney$School`),]
sorted_alpha_school$winner = (sorted_alpha_school$W.L. >= 0.5) * 1
View(sorted_alpha_school)
sorted_alpha_school
