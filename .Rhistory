<<<<<<< Updated upstream
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F)
cols <- c("Simple OLS"='#EE3838',"Segmented OLS"='#78C4D4')
p <- p + geom_line(data = my.model, aes(x = year, y = X3PAr))
p <- p + scale_colour_manual(name="Model Type",values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F) +
geom_line(data = my.model, aes(x = year, y = X3PAr), color = '#78C4D4') +
scale_colour_manual(name="Model Type",values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F) +
geom_line(data = my.model, aes(x = year, y = X3PAr), color = '#78C4D4', linetype = "solid") +
scale_colour_manual(name="Model Type",values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F,size=10) +
geom_line(data = my.model, aes(x = year, y = X3PAr), color = '#78C4D4', linetype = "solid") +
scale_colour_manual(name="Model Type",values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F,size=.1) +
geom_line(data = my.model, aes(x = year, y = X3PAr), color = '#78C4D4', linetype = "solid") +
scale_colour_manual(name="Model Type",values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
# Replot things
cols <- c("Simple OLS"='#EE3838',"Segmented OLS"='#78C4D4')
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F,size=.1) +
geom_line(data = my.model, aes(x = year, y = X3PAr),
color = '#78C4D4', linetype = "solid", size=.1) +
scale_colour_manual(name="Model Type",values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
# Replot things
cols <- c("Simple OLS"='#EE3838',"Segmented OLS"='#78C4D4')
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr),
color = '#78C4D4', linetype = "solid", size=1) +
scale_colour_manual(name="Model Type",values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr),
color = '#78C4D4', linetype = "solid", size=1) +
scale_colour_manual(name="Model Type",values=cols, guide = guide_legend(fill = NULL,colour = NULL))  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
# Replot things
cols <- c("Simple OLS"='#EE3838',"Segmented OLS"='#78C4D4')
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr,color = '#78C4D4'),
linetype = "solid", size=1) +
scale_colour_manual(name="Model Type",values=cols, guide = guide_legend(fill = NULL,colour = NULL))  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr),
color = '#78C4D4', linetype = "solid", size=1) +
scale_colour_manual(name="Model Type",values=cols, guide = guide_legend(fill = NULL,colour = NULL))  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", aes(col = '#EE3838'), se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr),
aes(color = '#78C4D4'), linetype = "solid", size=1) +
scale_colour_manual(name="Model Type",
values=cols)  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", aes(col = '#EE3838'), se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr, color = '#78C4D4'),
linetype = "solid", size=1) +
scale_colour_identity(name="Model Type",
breaks = c('#EE3838','#78C4D4'),
labels = c("Simple OLS", "Segmented OLS"),
guide = "legend")  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = NA)
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = NA)
summary(seg5)
pscore.test(seg4, ~time)
# VERY LIKELY TO HAVE A BREAKPOINT
pscore.test(seg4, ~time, more.break = T)
davies.test(seg4, ~time)
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = NA)
summary(seg5)
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = NA)
2008-2003
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = c(5,10))
summary(seg5)
df.tourney$X3PAr * df.tourney$FGA
### Test for BREAKPOINT
davies.test(lm1, ~time)
# Check for existence of one breakpoint using the pscore.test command
pscore.test(lm1, ~time)
davies.test(lm1, ~time)$
?davies.test
davies.test(lm1, ~time)$
?davies.test
?davies.test
davies.test(lm1, ~time)$parameter
davies.test(seg4, ~time)
### Test for Breakpoints
davies.test(lm1, ~time)
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(9.5)))
seg6 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(9.5)))
# have to provide estimates for breakpoints.
# apriori guess of 10 based on Curry 2015 MVP season
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(10)))
summary(seg4)
seg6 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(9.5)))
davies.test(seg4, ~time)
seg7 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3.5, 9.5)))
davies.test(seg7, ~time)
2003 + 3
2003+10
# Then another, more significant breakpoint between 2012-2013 and 2013-2014 seasons
# Curry sets record for NBA 3's in 2012-13
# get breakpoints
seg7$psi
# get the slopes
slope(seg7)
# get the fitted data
my.fitted <- fitted(seg7)
my.model <- data.frame(year = df.tourney$year, X3PAr = my.fitted)
# plot the fitted model
ggplot(my.model, aes(x = year, y = X3PAr)) + geom_line()
seg7 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3, 9)))
davies.test(seg7, ~time)
# Then another, more significant breakpoint between 2012-2013 and 2013-2014 seasons
# Curry sets record for NBA 3's in 2012-13
# get breakpoints
seg7$psi
# get the slopes
slope(seg7)
# get the fitted data
my.fitted <- fitted(seg7)
my.model <- data.frame(year = df.tourney$year, X3PAr = my.fitted)
# plot the fitted model
ggplot(my.model, aes(x = year, y = X3PAr)) + geom_line()
### Test for Breakpoints
davies.test(lm1, ~time)
seg6 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(9.3)))
davies.test(seg4, ~time)
seg7 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(3.1, 9.3)))
davies.test(seg7, ~time)
# Then another, more significant breakpoint between 2012-2013 and 2013-2014 seasons
# Curry sets record for NBA 3's in 2012-13
# get breakpoints
seg7$psi
# Then another, more significant breakpoint between 2012-2013 and 2013-2014 seasons
# Curry sets record for NBA 3's in 2012-13
# get breakpoints
seg7$psi
# get the slopes
slope(seg7)
# get the fitted data
my.fitted <- fitted(seg7)
my.model <- data.frame(year = df.tourney$year, X3PAr = my.fitted)
# Then another, more significant breakpoint between 2012-2013 and 2013-2014 seasons
# Curry sets record for NBA 3's in 2012-13
# get breakpoints
seg7$psi
# get the slopes
slope(seg7)
# get the fitted data
seg7.fitted <- fitted(seg7)
seg7.fitted.df <- data.frame(year = df.tourney$year, X3PAr = my.fitted)
# plot the fitted model
ggplot(seg7.fitted.df, aes(x = year, y = X3PAr)) + geom_line()
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", aes(col = '#EE3838'), se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr, color = '#78C4D4'),
linetype = "solid", size=1) +
scale_colour_identity(name="Model Type",
breaks = c('#EE3838','#78C4D4'),
labels = c("Simple OLS", "Segmented OLS"),
guide = "legend")  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", aes(col = '#EE3838'), se = F,size=1) +
geom_line(data = seg7.fitted.df, aes(x = year, y = X3PAr, color = '#78C4D4'),
linetype = "solid", size=1) +
scale_colour_identity(name="Model Type",
breaks = c('#EE3838','#78C4D4'),
labels = c("Simple OLS", "Segmented OLS"),
guide = "legend")  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", aes(col = '#EE3838'), se = F,size=1) +
geom_line(data = seg7.fitted.df, aes(x = year, y = X3PAr, color = '#78C4D4'),
linetype = "solid", size=1) +
scale_colour_identity(name="Model Type",
breaks = c('#EE3838','#78C4D4'),
labels = c("Simple OLS", "Segmented OLS: 2 breaks"),
guide = "legend")  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
fitted(seg7)
seg7.fitted.df
View(seg7.fitted.df)
=======
indictor_random <- c()
for(i in range) {
if(row_random[1] == i || row_random[2] == i || row_random[3] == i) {
indictor_random <- c(indictor_random, 1)
}
else {
indictor_random <- c(indictor_random, 0)
}
}
# from problem 4f, N curl is unbiased
bias_ncurl <- 0
se_ncurl <- ((1000)^2)*var(sum(indictor_random/area_random))
mse_ncurl <- bias_ncurl^2 + se_ncurl^2
area_random
row_random <- sample(10, 3)
area_random <- (row_random)/55
range <- seq(1,10,1)
indictor_random <- c()
for(i in range) {
counter <- 1
if(row_random[1] == i || row_random[2] == i || row_random[3] == i) {
indictor_random <- c(indictor_random, 1/area_random[counter])
counter <- counter + 1
}
else {
indictor_random <- c(indictor_random, 0)
}
}
# from problem 4f, N curl is unbiased
bias_ncurl <- 0
se_ncurl <- ((1000)^2)*var(sum(indictor_random/area_random))
mse_ncurl <- bias_ncurl^2 + se_ncurl^2
row_random <- sample(10, 3)
area_random <- (row_random)/55
range <- seq(1,10,1)
indicator_random <- c()
for(i in range) {
counter <- 1
if(row_random[1] == i || row_random[2] == i || row_random[3] == i) {
indicator_random <- c(indicator_random, 1/area_random[counter])
counter <- counter + 1
}
else {
indicator_random <- c(indicator_random, 0)
}
}
# from problem 4f, N curl is unbiased
bias_ncurl <- 0
se_ncurl <- ((1000)^2)*var(sum(indicator_random))
mse_ncurl <- bias_ncurl^2 + se_ncurl^2
mse_ncurl
se_ncurl
bias_ncurl
((1000)^2)*var(sum(indicator_random))
indicator_random
sum(indicator_random)
bias_ncurl <- 0
se_ncurl <- ((1000)^2)*(sum(var(indicator_random)))
mse_ncurl <- bias_ncurl^2 + se_ncurl^2
se_ncurl
mse_ncurl
rbinom(3, 1000, sum(area_random))
sum(area_random)
qnorm(.05)
qnorm(.025)
prop.test(c(37, 50),c(76,133))
library(dplyr)
install.packages("dplyr")
tidyverse
install.packages("tidyverse")
batting = read.csv("data/mlb_batting_data.csv")
batting = read.csv("data/county_level_cancer.csv")
cancer = read.csv("data/county_level_cancer.csv")
batting = read.csv("data/mlb_batting_data.csv")
cancer = read.csv("data/county_level_cancer.csv")
# forward model
interceptmodel <- lm(cancer ~ 1, data = cancer)
fullmodel <- lm(cancer ~., data = cancer)
forwardmodel = step(interceptmodel, scope = formula(fullmodel), direction="forward", k=2, trace=0)
formula(forwardmodel)
# backward model
backwardmodel = step(fullmodel, direction = "backward", trace = 0)
formula(backwardmodel)
# stepwise model
stepwisemodel = step(interceptmodel, scope=list(lower = formula(interceptmodel), upper = formula(fullmodel)), direction = "both", trace = 0)
formula(stepwisemodel)
AIC(model1, forwardmodel, backwardmodel, stepwisemodel)
AIC(forwardmodel, backwardmodel, stepwisemodel)
unique_county = length(unique(cancer$county))
unique_county = length(unique(cancer$county))
unique_county
lapply(cancer[1:ncol(cancer)], FUN=hist)
lapply(cancer[1:ncol(cancer)], FUN=hist)
ncol(cancer)
lapply(cancer[1:ncol(cancer)-1], FUN=hist)
cancer[1:ncol(cancer)]
col = seq(1, 15, by =1)
lapply(cancer[1:ncol(cancer)], FUN=hist)
col = seq(1, 15, by =1)
#lapply(cancer[1:ncol(cancer)], FUN=hist)
hist(mtcars[,col])
col = seq(1, 15, by =1)
#lapply(cancer[1:ncol(cancer)], FUN=hist)
hist(mtcars[,col-1])
col = seq(1, 15, by =1)
#lapply(cancer[1:ncol(cancer)], FUN=hist)
hist(cancer[,col])
col = seq(1, 15, by =1)
#lapply(cancer[1:ncol(cancer)], FUN=hist)
hist(as.numeric(cancer[,col]))
library(reshape2)
library(ggplot2)
gg <- melt(cancer)
ggplot(gg, aes(x=value, fill=variable)) +
geom_histogram(binwidth=10)+
facet_grid(variable~.)
cancer = read.csv("data/county_level_cancer.csv")
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
cancer$state = as.factor(cancer$state)
cancer$county = as.factor(cancer$county)
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
cancer$state = as.factor(cancer$state)
cancer$county = as.factor(cancer$county)
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
cancer$state = as.factor(cancer$state)
cancer$county = as.factor(cancer$county)
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
cancer$state = as.factor(cancer$state)
cancer$county = as.factor(cancer$county)
cancer = read.csv("data/county_level_cancer.csv")
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
cancer$state = as.factor(cancer$state)
cancer$county = as.factor(cancer$county)
model1 = lm(cancer ~ inactivity, data = cancer)
summary(model1)
# forward model
interceptmodel <- lm(cancer ~ 1, data = cancer)
fullmodel <- lm(cancer ~., data = cancer)
forwardmodel = step(interceptmodel, scope = formula(fullmodel), direction="forward", k=2, trace=0)
formula(forwardmodel)
RMSE = function(y,yhat){
SSE = sum((y-yhat)^2)
return(sqrt(SSE/length(y)))
}
# test for histograms
hist(cancer$state)
# test for histograms
hist(cancer$population)
# test for histograms
hist(log(cancer$population)
# test for histograms
hist(log(cancer$population))
# test for histograms
# log transform population
hist(cancer$population <- log(cancer$population))
# test for histograms
# log transform population
hist(cancer$population <- log(cancer$population))
hist(cancer$hispanic <- cancer$hispanic)
hist(cancer$minority <- cancer$minority)
hist(cancer$female <- cancer$female)
hist(cancer$unemployed <- cancer$unemployed)
hist(cancer$income <- cancer$income)
hist(cancer$nodegree <- cancer$nodegree)
hist(cancer$bachelor <- cancer$bachelor)
hist(cancer$inactivity <- cancer$inactivity)
hist(cancer$obesity <- cancer$obesity)
hist(cancer$density <- cancer$density)
# test for histograms
# log transform population
hist(cancer$population <- log(cancer$population))
hist(cancer$hispanic <- cancer$hispanic)
hist(cancer$minority <- cancer$minority)
hist(cancer$female <- cancer$female)
hist(cancer$unemployed <- cancer$unemployed)
hist(cancer$income <- cancer$income)
hist(cancer$nodegree <- cancer$nodegree)
hist(cancer$bachelor <- cancer$bachelor)
hist(cancer$inactivity <- cancer$inactivity)
hist(cancer$obesity <- cancer$obesity)
hist(cancer$density <- log(cancer$density))
# test for histograms
# log transform population, hispanic, minority, density
hist(cancer$population <- log(cancer$population))
hist(cancer$hispanic <- log(cancer$hispanic))
hist(cancer$minority <- log(cancer$minority))
hist(cancer$female <- cancer$female)
hist(cancer$unemployed <- cancer$unemployed)
hist(cancer$income <- cancer$income)
hist(cancer$nodegree <- cancer$nodegree)
hist(cancer$bachelor <- cancer$bachelor)
hist(cancer$inactivity <- cancer$inactivity)
hist(cancer$obesity <- cancer$obesity)
hist(cancer$density <- log(cancer$density))
# test for histograms
# log transform population, hispanic, minority, density
hist(cancer$population <- log(cancer$population))
hist(cancer$hispanic <- log(cancer$hispanic))
hist(cancer$minority <- log(cancer$minority))
hist(cancer$female <- cancer$female)
hist(cancer$unemployed <- cancer$unemployed)
hist(cancer$income <- cancer$income)
hist(cancer$nodegree <- cancer$nodegree)
hist(cancer$bachelor <- cancer$bachelor)
hist(cancer$inactivity <- cancer$inactivity)
hist(cancer$obesity <- cancer$obesity)
hist(cancer$density <- log(cancer$density))
cancer = read.csv("data/county_level_cancer.csv")
RMSE = function(y,yhat){
SSE = sum((y - yhat)^2)
return(sqrt(SSE/length(y)))
}
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
cancer$state = as.factor(cancer$state)
cancer$county = as.factor(cancer$county)
# test for histograms
# log transform population, hispanic, minority, density
hist(cancer$population <- log(cancer$population))
hist(cancer$hispanic <- log(cancer$hispanic))
hist(cancer$minority <- log(cancer$minority))
hist(cancer$female <- cancer$female)
hist(cancer$unemployed <- cancer$unemployed)
hist(cancer$income <- cancer$income)
hist(cancer$nodegree <- cancer$nodegree)
hist(cancer$bachelor <- cancer$bachelor)
hist(cancer$inactivity <- cancer$inactivity)
hist(cancer$obesity <- cancer$obesity)
hist(cancer$density <- log(cancer$density))
# fit the intercept and the full model
interceptmodel <- lm(cancer ~ 1, data = cancer)
fullmodel <- lm(cancer ~., data = cancer)
summary(fullmodel)
library(lme4)
cancer_mm = lmer(cancer ~ inactivity | county), data=cancer))
library(lme4)
cancer_mm = lmer(cancer ~ inactivity | county, data=cancer)
cancer = read.csv("data/county_level_cancer.csv")
library(lme4)
cancer_mm = lmer(cancer ~ inactivity | county, data=cancer)
cancer = read.csv("data/county_level_cancer.csv")
library(lme4)
cancer_mm = lmer(cancer ~ inactivity | county, data=cancer)
RMSE = function(y,yhat){
SSE = sum((y - yhat)^2)
return(sqrt(SSE/length(y)))
}
drops <- c("fipscode")
cancer = cancer[ , !(names(cancer) %in% drops)]
cancer$state = as.factor(cancer$state)
cancer$county = as.factor(cancer$county)
# test for histograms
# log transform population, hispanic, minority, density
hist(cancer$population <- log(cancer$population))
hist(cancer$hispanic <- log(cancer$hispanic))
hist(cancer$minority <- log(cancer$minority))
hist(cancer$female <- cancer$female)
hist(cancer$unemployed <- cancer$unemployed)
hist(cancer$income <- cancer$income)
hist(cancer$nodegree <- cancer$nodegree)
hist(cancer$bachelor <- cancer$bachelor)
hist(cancer$inactivity <- cancer$inactivity)
hist(cancer$obesity <- cancer$obesity)
hist(cancer$density <- log(cancer$density))
model1 = lm(cancer ~ inactivity, data = cancer)
summary(model1)
# fit the intercept and the full model
interceptmodel <- lm(cancer ~ 1, data = cancer)
fullmodel <- lm(cancer ~., data = cancer)
# summary(fullmodel)
library(tidyverse)
flights_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
View(flights_residuals)
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res = mean(resid)) %>%
ggplot(cancer, mapping = aes(x = county, y = mean_res))
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res = mean(resid)) %>%
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res = mean(resid))
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res = mean(resid)) %>%
ggplot(cancer, mapping = aes(x = county, y = mean_res)) +
geom_bar(stat="identity")
qqplot(mean_res)
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res <- mean(resid)) %>%
ggplot(cancer, mapping = aes(x = county, y = mean_res)) +
geom_bar(stat="identity")
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res <- mean(resid)) %>%
ggplot(cancer, mapping = aes(x = county, y = mean_res)) +
geom_bar(stat="identity")
library(tidyverse)
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res <- mean(resid)) %>%
ggplot(cancer, mapping = aes(x = county, y = mean_res)) +
geom_bar(stat="identity")
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
# boxplot for carriers
cancer_residuals %>%
group_by(county) %>%
summarise(mean_res = mean(resid)) %>%
ggplot(cancer, mapping = aes(x = county, y = mean_res)) +
geom_bar(stat="identity")
qqplot(mean(resid))
qqplot(model1$residuals)
qqnorm(model1$residuals)
library(glmnet)
install.packages("glmnet")
install.packages("glmnet")
R.version.string
install.packages('glmnet',repos='http://cran.us.r-project.org')
library(glmnet)
ridges = cv.glmnet(cancer, cancer$cancer, alpha = 0)
install.packages("glmnet", dependencies=TRUE)
# check assumptions
cancer_residuals = cbind(cancer, resid = resid(model1), fitted = fitted(model1))
qqnorm(model1$residuals)
install.packages(c("assertthat", "backports", "boot", "callr", "class", "cli", "clipr", "cluster", "codetools", "colorspace", "curl", "devtools", "digest", "evaluate", "foreach", "foreign", "fs", "ggplot2", "git2r", "glue", "gtable", "haven", "htmltools", "httr", "iterators", "KernSmooth", "knitr", "lazyeval", "markdown", "MASS", "Matrix", "mgcv", "mime", "nlme", "openssl", "openxlsx", "pbapply", "pillar", "pkgbuild", "pkgconfig", "processx", "purrr", "R6", "rcmdcheck", "Rcpp", "remotes", "rlang", "rmarkdown", "rpart", "rvest", "scales", "selectr", "SimDesign", "stringi", "stringr", "survival", "sys", "testthat", "tidyverse", "tinytex", "usethis", "VGAM", "whisker", "xfun", "zip"))
install.packages("glmnet", dependencies=TRUE)
# Jess, Anna and Seth Project
# 11/29/19
source('styleguide.R')
source('helpers.R')
# Packages for optimizers
if (!require('optimx')) install.packages('optimx'); library(optimx)
if (!require('parallel')) install.packages('parallel'); library(parallel)
if (!require('minqa')) install.packages('minqa'); library(minqa)
if (!require('lme4')) install.packages('lme4'); library(lme4) # for mixed models
if (!require('segmented')) install.packages('segmented'); library(segmented)
df.clean <- add_time("complete_data_clean.csv")
df.tourney <- add_time("tourney_data_clean.csv")
>>>>>>> Stashed changes
# Jess, Anna and Seth Project
# 11/29/19
source('styleguide.R')
source('helpers.R')
# Packages for optimizers
if (!require('optimx')) install.packages('optimx'); library(optimx)
if (!require('parallel')) install.packages('parallel'); library(parallel)
if (!require('minqa')) install.packages('minqa'); library(minqa)
if (!require('lme4')) install.packages('lme4'); library(lme4) # for mixed models
if (!require('segmented')) install.packages('segmented'); library(segmented)
df.clean <- add_time("complete_data_clean.csv")
df.tourney <- add_time("tourney_data_clean.csv")
<<<<<<< Updated upstream
# Check dimensions - len(unique schools) * len(unique years) must equal # of rows
dim_checker(df.clean)
dim_checker(df.tourney)
=======
# Packages for optimizers
if (!require('optimx')) install.packages('optimx'); library(optimx)
# Jess, Anna and Seth Project
# 11/29/19
setwd("stat139finalproject/") # for jess only
source('styleguide.R')
source('helpers.R')
# Packages for optimizers
if (!require('optimx')) install.packages('optimx'); library(optimx)
if (!require('parallel')) install.packages('parallel'); library(parallel)
if (!require('minqa')) install.packages('minqa'); library(minqa)
if (!require('lme4')) install.packages('lme4'); library(lme4) # for mixed models
if (!require('segmented')) install.packages('segmented'); library(segmented)
df.clean <- add_time("complete_data_clean.csv")
df.tourney <- add_time("tourney_data_clean.csv")
# Check dimensions - len(unique schools) * len(unique years) must equal # of rows
dim_checker(df.clean)
dim_checker(df.tourney)
# since we know that games are increasing can we make those statistics into proportions to control
# for the specific effect
get_newprop = cbind(df.tourney$School, get_prop_df(df.tourney))
get_newprop
>>>>>>> Stashed changes
# Let's have X3PAr be our response
# Check assumption of normal distribution
p <- ggplot(df.tourney, aes(x=X3PAr)) +
geom_histogram(colour="black", fill='#EE3838') +
labs(title="3PAr Histogram") +
xlab("3PAr") +
ylab("Counts") +
theme_hodp()
<<<<<<< Updated upstream
dim_checker(df.tourney)
=======
p
>>>>>>> Stashed changes
# Let's have X3PAr be our response
# Check assumption of normal distribution
p <- ggplot(df.tourney, aes(x=X3PAr)) +
geom_histogram(colour="black", fill='#EE3838') +
labs(title="3PAr Histogram") +
xlab("3PAr") +
ylab("Counts") +
theme_hodp()
<<<<<<< Updated upstream
p
# Model 1: pool all teams together, OLS model for 3PAr change over time
lm1 <- lm(X3PAr ~ time, df.tourney)
summary(lm1)
names(df.clean)
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F) +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
# Model 2: Mixed Model, fixed effect of time
lmer2 <- lmer(X3PAr ~ time + (1 | School), data=df.tourney)
summary(lmer2)
coef(summary(lmer2))
coef(lmer2)$School
### Fitting a random slopes, random intercepts model is often failing to converge
lmer3 <- lmer(X3PAr ~ time + (1|School) + (time|School), data=df.tourney)
# list of convergence failures...
lmer3a <- update(lmer3,
REML = FALSE,
control = lmerControl(
optimizer ='optimx', optCtrl=list(method='L-BFGS-B')))
lmer3b <- update(lmer3,
control=lmerControl(optCtrl=list(ftol_abs=1e-8,xtol_abs=1e-8)))
# Model 2: Mixed Model, fixed effect of time
lmer2 <- lmer(X3PAr ~ time + (1 | School), data=df.tourney)
summary(lmer2)
coef(summary(lmer2))
coef(lmer2)$School
### Fitting a random slopes, random intercepts model is often failing to converge
lmer3 <- lmer(X3PAr ~ time + (1|School) + (time|School), data=df.tourney)
# list of convergence failures...
lmer3a <- update(lmer3,
REML = FALSE,
control = lmerControl(
optimizer ='optimx', optCtrl=list(method='L-BFGS-B')))
lmer3b <- update(lmer3,
control=lmerControl(optCtrl=list(ftol_abs=1e-8,xtol_abs=1e-8)))
lmer3c <- update(lmer3, control=lmerControl(optimizer="bobyqa"))
# Use all fit to find a model that converges
# Source: https://joshua-nugent.github.io/allFit/
ncores <- detectCores()
diff_optims <- allFit(lmer3, maxfun = 1e6, parallel = 'multicore', ncpus = ncores)
is.OK <- sapply(diff_optims, is, "merMod")
diff_optims.OK <- diff_optims[is.OK]
lapply(diff_optims.OK,function(x) x@optinfo$conv$lme4$messages)
### Nelder_Mead converges successfully!!! - but only for the df.tourney
lmer3d <- update(lmer3, control=lmerControl(optimizer="Nelder_Mead"))
# Summary
summary(lmer3d)
### COMPARE
# Fixed coefs
coef(summary(lmer2))
coef(summary(lmer3d))
# Look at differences b/w individual schools coefs
coef(lmer2)$School
coef(lmer3d)$School
head(coef(lmer3d)$School)
head(coef(lmer2)$School)
head(coef(lmer3d)$School)
# Unsurprisingly, our random slopes and intercepts model is significantly better than
# our simple random intercepts model. It may be even more overfit though.
anova(lmer2,lmer3)
# Unsurprisingly, our random slopes and intercepts model is significantly better than
# our simple random intercepts model. It may be even more overfit though.
anova(lmer2,lmer3d)
### Let's do some plots
# Get coefficients
year <- 2003:2017
intercept.mm <- summary(lmer3d)$coef[1,1]
slope.mm <- summary(lmer3d)$coef[2,1]
lmer3fn <- function(year) {
return(intercept.mm + (year - 2003) * slope.mm)
}
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", col = '#EE3838', se = F) +
geom_segment(aes(x = 2003, y = lmer3fn(2003), xend = 2017, yend = lmer3fn(2017), colour = "yellow"),
data = df.tourney) +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
#ylim(c(0,0.6)) +
theme_hodp()
p
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 10 based on Curry 2015 MVP season
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(10)))
summary(seg4)
# display the summary
summary(seg4)
### SEGMENTED REGRESSION ###
# Using the segmented package
# have to provide estimates for breakpoints.
# apriori guess of 10 based on Curry 2015 MVP season,
seg4 <- segmented(lm1,
seg.Z = ~ time,
psi = list(time = c(10)))
summary(seg4)
# display the summary
summary(seg4)
# get breakpoints
seg4$psi
# get the slopes
slope(seg4)
# get the fitted data
my.fitted <- fitted(seg4)
my.model <- data.frame(year = df.tourney$year, X3PAr = my.fitted)
# plot the fitted model
ggplot(my.model, aes(x = year, y = X3PAr)) + geom_line()
# Replot things
cols <- c("Simple OLS"='#EE3838',"Segmented OLS"='#78C4D4')
p <- ggplot(df.tourney, aes(x = time + 2003, y = X3PAr)) +
geom_point() +
stat_smooth(method = "lm", aes(col = '#EE3838'), se = F,size=1) +
geom_line(data = my.model, aes(x = year, y = X3PAr, color = '#78C4D4'),
linetype = "solid", size=1) +
scale_colour_identity(name="Model Type",
breaks = c('#EE3838','#78C4D4'),
labels = c("Simple OLS", "Segmented OLS break between 9 and 10"),
guide = "legend")  +
labs(title="3PAr Over Time - Pooled") +
xlab("Year") +
ylab("3PAr") +
theme_hodp()
p
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = c(5,10))
summary(seg5)
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = c(5,10))
summary(seg5)
# Let's try to find segements using psi = NA
# This will iteratively try to find breakpoints though its likely to overestimate
# the appropriate number
seg5 <- segmented(lm1,
seg.Z = ~ time,
psi = c(3,10))
summary(seg5)
=======
source('styleguide.R')
# Let's have X3PAr be our response
# Check assumption of normal distribution
p <- ggplot(df.tourney, aes(x=X3PAr)) +
geom_histogram(colour="black", fill='#EE3838') +
labs(title="3PAr Histogram") +
xlab("3PAr") +
ylab("Counts") +
theme_hodp()
p
#### Most Recent Debate ####
# Step 0: HODP Theme
if (!require('dplyr')) install.packages('dplyr'); library(dplyr)
if (!require('ggplot2')) install.packages('ggplot2'); library(ggplot2)
if (!require('hrbrthemes')) install.packages('hrbrthemes'); library(hrbrthemes)
if (!require('magick')) install.packages('magick'); library(magick)
if (!require('plotly')) install.packages('plotly'); library(plotly)
# Legend: https://stackoverflow.com/questions/14622421/how-to-change-legend-title-in-ggplot
monochrome <- c('#760000', '#BE1E26', '#D84742', '#FF6B61', '#FF9586')
primary <- c('#EE3838', '#FA9E1C', '#78C4D4', '#4B5973', '#E2DDDB')
sidebysidebarplot <- c("#ef3e3e", "#2c3e50")
theme_hodp <- function () {
theme_classic(base_size=12, base_family="Helvetica") %+replace%
theme(
panel.background  = element_rect(fill="#F2F2F2", colour=NA),
plot.background = element_rect(fill="#F2F2F2", colour="#d3d3d3"),
legend.background = element_rect(fill="transparent", colour=NA),
legend.key = element_rect(fill="transparent", colour=NA),
plot.title = element_text(size=24,  family="Helvetica", face = "bold", margin = margin(t = 0, r = 0, b = 10, l = 0)),
plot.subtitle = element_text(size=18,  family="Helvetica", color="#717171", face = "italic", margin = margin(t = 0, r = 0, b = 10, l = 0)),
plot.caption = element_text(size=8,  family="Helvetica", hjust = 1),
axis.text.x =element_text(size=10,  family="Helvetica"),
axis.title.x =element_text(size=14, family="Helvetica", margin = margin(t = 10, r = 0, b = 0, l = 0), face = "bold"),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0), size=14, family="Helvetica", angle=90, face ='bold'),
legend.title=element_text(size=10, family="Helvetica"),
legend.text=element_text(size=10, family="Helvetica"),
legend.position = "bottom",
axis.ticks = element_blank()
)
}
source('styleguide.R')
if (!require('hrbrthemes')) install.packages('hrbrthemes'); library(hrbrthemes)
#### Most Recent Debate ####
# Step 0: HODP Theme
if (!require('dplyr')) install.packages('dplyr'); library(dplyr)
if (!require('ggplot2')) install.packages('ggplot2'); library(ggplot2)
if (!require('hrbrthemes')) install.packages('hrbrthemes'); library(hrbrthemes)
update.packages(checkBuilt=TRUE, ask=FALSE)
setwd("stat139finalproject/") # for jess only
source('styleguide.R')
source('helpers.R')
df.clean <- add_time("complete_data_clean.csv")
df.tourney <- add_time("tourney_data_clean.csv")
# Check dimensions - len(unique schools) * len(unique years) must equal # of rows
dim_checker(df.clean)
dim_checker(df.tourney)
# since we know that games are increasing can we make those statistics into proportions to control
# for the specific effect
get_newprop = cbind(df.tourney$School, get_prop_df(df.tourney))
get_newprop
# Let's have X3PAr be our response
# Check assumption of normal distribution
p <- ggplot(df.tourney, aes(x=X3PAr)) +
geom_histogram(colour="black", fill='#EE3838') +
labs(title="3PAr Histogram") +
xlab("3PAr") +
ylab("Counts") +
theme_hodp()
p
p
setwd("stat139finalproject/") # for jess only
source('styleguide.R')
source('helpers.R')
# Packages for optimizers
if (!require('optimx')) install.packages('optimx'); library(optimx)
if (!require('parallel')) install.packages('parallel'); library(parallel)
if (!require('minqa')) install.packages('minqa'); library(minqa)
if (!require('lme4')) install.packages('lme4'); library(lme4) # for mixed models
if (!require('segmented')) install.packages('segmented'); library(segmented)
# https://cran.r-project.org/web/packages/segmented/segmented.pdf
# Read in Clean DF
df.clean <- add_time("complete_data_clean.csv")
df.tourney <- add_time("tourney_data_clean.csv")
# Check dimensions - len(unique schools) * len(unique years) must equal # of rows
dim_checker(df.clean)
dim_checker(df.tourney)
# since we know that games are increasing can we make those statistics into proportions to control
# for the specific effect
get_newprop = cbind(df.tourney$School, get_prop_df(df.tourney))
get_newprop
# Let's have X3PAr be our response
# Check assumption of normal distribution
p <- ggplot(df.tourney, aes(x=X3PAr)) +
geom_histogram(colour="black", fill='#EE3838') +
labs(title="3PAr Histogram") +
xlab("3PAr") +
ylab("Counts") +
theme_hodp()
p
>>>>>>> Stashed changes
